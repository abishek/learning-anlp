{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "basics.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/abishek/learning-anlp/blob/master/basics.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ppqzoQgwvwLl",
        "colab_type": "text"
      },
      "source": [
        "Understanding and implementing TF-IDF for a corpus."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Jszj7CaTQIRD",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 306
        },
        "outputId": "d2e88db8-3f02-4a7f-e58d-ec91c2dc31f0"
      },
      "source": [
        "import nltk\n",
        "nltk.download('stopwords')\n",
        "nltk.download('gutenberg')\n",
        "nltk.download('shakespeare')\n",
        "from nltk.probability import FreqDist\n",
        "from nltk.corpus import stopwords, shakespeare\n",
        "import pandas as pd\n",
        "\n",
        "# shakespeare corpus has a few plays in it. let me pick the first one.\n",
        "play_to_use = shakespeare.fileids()[0]\n",
        "\n",
        "\n",
        "stop_words = set(stopwords.words('english'))\n",
        "#read the corpus\n",
        "words = nltk.Text(nltk.corpus.shakespeare.words(play_to_use))\n",
        "#convert to small letters\n",
        "words=[word.lower() for word in words if word.isalpha() ]\n",
        "words=[word.lower() for word in words if word not in stop_words ]\n",
        "fDist = FreqDist(words)\n",
        "\n",
        "heading = ['Word','Frequency']\n",
        "tf_list = []\n",
        "for x,v in fDist.most_common(10):\n",
        "    tf_list.append((x,v))\n",
        "print(pd.DataFrame(tf_list,columns=heading))"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Package stopwords is already up-to-date!\n",
            "[nltk_data] Downloading package gutenberg to /root/nltk_data...\n",
            "[nltk_data]   Package gutenberg is already up-to-date!\n",
            "[nltk_data] Downloading package shakespeare to /root/nltk_data...\n",
            "[nltk_data]   Package shakespeare is already up-to-date!\n",
            "        Word  Frequency\n",
            "0     antony        387\n",
            "1     caesar        290\n",
            "2  cleopatra        274\n",
            "3       mark        264\n",
            "4       thou        182\n",
            "5  enobarbus        152\n",
            "6   domitius        140\n",
            "7   octavius        133\n",
            "8      shall        127\n",
            "9      enter        112\n"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}